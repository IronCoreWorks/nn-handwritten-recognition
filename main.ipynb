{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "print(\"Setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.load(\"data/X.npy\")\n",
    "    y = np.load(\"data/y.npy\")\n",
    "    X = X[0:1000]\n",
    "    y = y[0:1000]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"The first element of X is: \", X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The first element of y is: \", y[0, 0])\n",
    "# print(\"The last element of y is: \", y[-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# m, n = X.shape\n",
    "\n",
    "# fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "# fig.tight_layout(pad=0.1)\n",
    "\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     random_index = np.random.randint(m)\n",
    "#     X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "#     ax.imshow(X_random_reshaped, cmap=\"gray\")\n",
    "#     ax.set_title(y[random_index, 0])\n",
    "#     ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(400,)),\n",
    "        Dense(25, activation=\"sigmoid\"),\n",
    "        Dense(15, activation=\"sigmoid\"),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"hdr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.5271\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 634us/step - loss: 0.1937\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 620us/step - loss: 0.0789\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 532us/step - loss: 0.0435\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 566us/step - loss: 0.0296\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0228\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 584us/step - loss: 0.0188\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 552us/step - loss: 0.0162\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 548us/step - loss: 0.0144\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 508us/step - loss: 0.0130\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 550us/step - loss: 0.0120\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 562us/step - loss: 0.0112\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 565us/step - loss: 0.0106\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 557us/step - loss: 0.0100\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 572us/step - loss: 0.0094\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 564us/step - loss: 0.0083\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 551us/step - loss: 0.0087\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 526us/step - loss: 0.0050\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 513us/step - loss: 0.0035\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 496us/step - loss: 0.0031\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 520us/step - loss: 0.0028\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 509us/step - loss: 0.0026\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 514us/step - loss: 0.0024\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 512us/step - loss: 0.0022\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 502us/step - loss: 0.0020\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 513us/step - loss: 0.0019\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 525us/step - loss: 0.0018\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 522us/step - loss: 0.0017\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 518us/step - loss: 0.0016\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 531us/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x291358810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.005),\n",
    ")\n",
    "\n",
    "model.fit(X, y, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model on an example to make a prediction, use [Keras `predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model). The input to `predict` is an array so the single example is reshaped to be two dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# prediction = model.predict(X[0].reshape(1, 400))  # a zero\n",
    "# print(f\" predicting a zero: {prediction}\")\n",
    "# prediction = model.predict(X[500].reshape(1, 400))  # a one\n",
    "# print(f\" predicting a one:  {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model is interpreted as a probability. In the first example above, the input is a zero. The model predicts the probability that the input is a one is nearly zero. \n",
    "In the second example, the input is a one. The model predicts the probability that the input is a one is nearly one.\n",
    "As in the case of logistic regression, the probability is compared to a threshold to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# if prediction >= 0.5:\n",
    "#     yhat = 1\n",
    "# else:\n",
    "#     yhat = 0\n",
    "# print(f\"prediction after threshold: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the predictions vs the labels for a random sample of 64 digits. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# # You do not need to modify anything in this cell\n",
    "\n",
    "# m, n = X.shape\n",
    "\n",
    "# fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "# fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92])  # [left, bottom, right, top]\n",
    "\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     # Select random indices\n",
    "#     random_index = np.random.randint(m)\n",
    "\n",
    "#     # Select rows corresponding to the random indices and\n",
    "#     # reshape the image\n",
    "#     X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "\n",
    "#     # Display the image\n",
    "#     ax.imshow(X_random_reshaped, cmap=\"gray\")\n",
    "\n",
    "#     # Predict using the Neural Network\n",
    "#     prediction = model.predict(X[random_index].reshape(1, 400))\n",
    "#     if prediction >= 0.5:\n",
    "#         yhat = 1\n",
    "#     else:\n",
    "#         yhat = 0\n",
    "\n",
    "#     # Display the label above the image\n",
    "#     ax.set_title(f\"{y[random_index,0]},{yhat}\")\n",
    "#     ax.set_axis_off()\n",
    "# fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0.99828273]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"test.png\")\n",
    "gray_image = image.convert(\"L\")\n",
    "resized_image = gray_image.resize((20, 20))\n",
    "image_array = np.array(resized_image).T\n",
    "\n",
    "plt.imshow(image_array.T, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "prediction = model.predict(image_array.reshape(1, 400))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(\"test2.png\")\n",
    "# gray_image = image.convert(\"L\")\n",
    "# resized_image = gray_image.resize((20, 20))\n",
    "# image_array = np.array(resized_image).T\n",
    "# image_array = 255 - image_array\n",
    "\n",
    "# plt.imshow(image_array.T, cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# prediction = model.predict(image_array.reshape(1, 400))\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
